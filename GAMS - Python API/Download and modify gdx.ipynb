{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3abc13ea-4fd0-4016-9b5d-8c4577b1a815",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "def update_package(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", package])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af7aea4a-568a-464f-afad-85557ccfa9e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "update_package(\"pip\")\n",
    "install(\"gamsapi\")\n",
    "install(\"gamsapi[transfer]==48.6.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "069dbba1-ca6d-42dd-855c-56456fba2c26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gams.transfer as gt\n",
    "import gams as g\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c0e3d78-3b76-49ab-be30-c9cf67bed30f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sysdir = '/Volumes/datahub/marketmonitoring/marketmonitoring/Corey/Programs/gams48.6_linux_x64_64_sfx'\n",
    "vSPD = '/Volumes/datahub/marketmonitoring/marketmonitoring/Corey/vSPD'\n",
    "InputDir = vSPD + '/Input/'\n",
    "OutputDir = vSPD + '/Output/'\n",
    "output_prefix = \"Modified_\"\n",
    "pnode_todup = ['KOE1101 KSF0']\n",
    "pnode_dup = ['KOE1101 KSF2']\n",
    "\n",
    "os.makedirs(os.path.dirname(InputDir), exist_ok=True)\n",
    "os.makedirs(os.path.dirname(OutputDir), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34ed979f-a695-4d00-83f8-7f855d9fea5c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Downloads all gdx files within a spefic web page\n",
    "\n",
    "def DownloadGdx(url):\n",
    "  # Send a request to the URL\n",
    "  response = requests.get(url)\n",
    "\n",
    "  # Parse the HTML response using BeautifulSoup\n",
    "  soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "  # Find all the links on the page\n",
    "  links = soup.find_all('a')\n",
    "\n",
    "  # Loop through the links filters to get all of the gdx files \n",
    "  FileList =  []\n",
    "  BaseList = []\n",
    "  for link in links:\n",
    "      href = link.get('href')\n",
    "      if href is not None and href.endswith('.gdx'):\n",
    "          FileList.append(href)\n",
    "          BaseList.append(os.path.basename(href).split('.')[0])\n",
    "\n",
    "\n",
    "  # Sort all the files alphanumerically and gets rid of all of the duplicates\n",
    "  FileList = sorted(list(set(FileList)))\n",
    "  BaseList = sorted(list(set(BaseList)))\n",
    "\n",
    "  # Downloads all gdx files, fixing all of the incorrectly named files\n",
    "  for i in range(len(FileList)):\n",
    "    dbutils.fs.cp('https://www.emi.ea.govt.nz' + FileList[i], InputDir) # downloads to mount point\n",
    "\n",
    "# Set the URL to request\n",
    "url = 'https://www.emi.ea.govt.nz/Wholesale/Datasets/DispatchAndPricing/GDX/2025'  \n",
    "DownloadGdx(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "465473ef-31a3-4fc9-88cf-8970897105ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "BaseList = [f for f in os.listdir(InputDir) if os.path.isfile(os.path.join(InputDir, f))]\n",
    "DateList = [s.split('_', 1)[1] if '_' in s else s for s in BaseList]\n",
    "DateList[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20de1edc-ab4c-4ee7-bf2b-7dd7d84f1c50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create a GAMS workspace\n",
    "ws = g.GamsWorkspace(system_directory=sysdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90e9f246-885c-4916-abd4-c012497f5a1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(BaseList)):\n",
    "    print(i+1, 'of', len(BaseList))\n",
    "\n",
    "    # Read the GDX file\n",
    "    inputFile = InputDir + BaseList[i]\n",
    "    m = gt.Container(inputFile, system_directory=sysdir)\n",
    "\n",
    "    # Initialize lists to store sets and parameters\n",
    "    sets = []\n",
    "    parameters = []\n",
    "    s_and_p = []\n",
    "\n",
    "    # Iterate through the symbols in the GDX file and create a dictionary of dataframes and indicators of whether they are parameters or sets\n",
    "    AllDFs = {}\n",
    "    RecordDisc = {}\n",
    "    for symbol in m:\n",
    "        j = symbol[0]\n",
    "        s_and_p.append(j)\n",
    "        RecordDisc[j] = m[j]._description\n",
    "        if m.data[j].records is None:\n",
    "            if m[j]._gams_type == 0:\n",
    "                AllDFs[j] = pd.DataFrame(columns = m.data[j].domain)   \n",
    "            else:\n",
    "                AllDFs[j] = pd.DataFrame(columns = m.data[j].domain + ['Value'])   \n",
    "        else: \n",
    "            if m[j]._gams_type == 0:\n",
    "                AllDFs[j] = m.data[j].records[m.data[j].domain_labels].copy(deep=True)\n",
    "            else:\n",
    "                AllDFs[j] = m.data[j].records.copy(deep=True)\n",
    "\n",
    "        if m[j]._gams_type == 0:\n",
    "            sets.append(j)\n",
    "        elif m[j]._gams_type == 1:\n",
    "            parameters.append(j)\n",
    "\n",
    "\n",
    "    # go through each dataframes to find the sets and parameters that need to be duplicated (we are adding another large solar plant in kaitaia except it is 5x larger)\n",
    "    n_list = []\n",
    "    o_list = []\n",
    "\n",
    "    for s_name, df in AllDFs.items():\n",
    "        col_names = df.columns\n",
    "\n",
    "        if 'n' in col_names: \n",
    "            n_list += [s_name]\n",
    "        if 'o' in col_names: \n",
    "            o_list += [s_name]\n",
    "\n",
    "    # The i_node set is the only set where the n set is labelled as *\n",
    "    i_node = AllDFs['i_node']\n",
    "    for j in range(len(pnode_todup)):\n",
    "        i_node['uni'] = i_node['uni'].cat.add_categories(pnode_dup[j])\n",
    "        i_node_todup = i_node[i_node['uni'] == pnode_todup[j]].copy()\n",
    "        i_node_todup.loc[i_node_todup['uni'] == pnode_todup[j], 'uni'] = pnode_dup[j]\n",
    "        AllDFs['i_node'] = pd.concat([AllDFs['i_node'], i_node_todup]).reset_index(drop=True)\n",
    "\n",
    "    # Iterate through and duplicate\n",
    "    for symbol_name, df in AllDFs.items():\n",
    "        dup_cols = list(set(df.columns) & set(['n','o']))\n",
    "        if symbol_name in list(set(n_list) | set(o_list)):\n",
    "            for j in range(len(pnode_todup)):\n",
    "                dupDF = pd.DataFrame()\n",
    "                tempDF = df[df[dup_cols[0]] == pnode_todup[j]].copy()\n",
    "                dupDF = pd.concat([dupDF,tempDF])\n",
    "                    \n",
    "                for col in dup_cols:      \n",
    "                    dupDF[col] = dupDF[col].astype('object')\n",
    "                    dupDF.loc[:,col] = pnode_dup[j]\n",
    "\n",
    "                if len(dupDF) > 0:\n",
    "                    df = pd.concat([df,dupDF]).reset_index(drop=True)       \n",
    "        AllDFs[symbol_name] = df.copy()    \n",
    "\n",
    "\n",
    "    for pn in pnode_dup:\n",
    "        df = AllDFs['i_dateTimeEnergyOffer'].copy()\n",
    "        df.loc[(df['o'] == pn) & (df['bidofrCmpnt'] == 'limitMW'), 'value'] *= 3.0 \n",
    "        AllDFs['i_dateTimeEnergyOffer'] = df.copy()\n",
    "\n",
    "        df = AllDFs['i_dateTimeOfferParameter'].copy()\n",
    "        df.loc[(df['o'] == pn) & (df['offerPar'].isin(['initialMW','resrvGenMax','potentialMW'])),'value'] *= 3.0\n",
    "        AllDFs['i_dateTimeOfferParameter'] = df.copy()\n",
    "\n",
    "    outputFile = OutputDir + output_prefix + DateList[i]\n",
    "\n",
    "    m = gt.Container(system_directory=sysdir)\n",
    "    for j in s_and_p:\n",
    "        if j in sets:\n",
    "            colnames = ['*' if col == 'uni' else col for col in AllDFs[j].columns]\n",
    "            gt.Set(m, j, colnames, records = AllDFs[j], description=RecordDisc[j])\n",
    "\n",
    "        if j in parameters:\n",
    "            colnames = ['*' if col == 'uni' else col for col in AllDFs[j].columns]\n",
    "            gt.Parameter(m, j, colnames[0:-1], records = AllDFs[j])\n",
    "\n",
    "\n",
    "    m.write(outputFile)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Download and modify gdx",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
